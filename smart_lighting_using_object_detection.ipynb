{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by micheal sichilongo\n",
    "#michealsichilongo@gmail.com\n",
    "#youtube: @michealsichilongo\n",
    "\n",
    "import serial\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Define the serial port and baud rate\n",
    "portVar = '/dev/ttyUSB0'  # Manually set the port to '/dev/ttyUSB0'\n",
    "serialInst = serial.Serial()\n",
    "serialInst.baudrate = 9600\n",
    "serialInst.port = portVar\n",
    "\n",
    "try:\n",
    "    serialInst.open()\n",
    "    print(f\"Connected to {portVar}\")\n",
    "except serial.SerialException:\n",
    "    print(f\"Failed to connect to {portVar}. Check the port or connection.\")\n",
    "    exit()\n",
    "\n",
    "def send_command_to_arduino(command):\n",
    "    if command != '':\n",
    "        serialInst.write(command.encode('utf-8'))  # Send the command to Arduino\n",
    "\n",
    "def tflite_realtime_detection(modelpath, lblpath, min_conf=0.5):\n",
    "    # Load the label map into memory\n",
    "    with open(lblpath, 'r') as f:\n",
    "        labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    # Load the TensorFlow Lite model into memory and specify the number of threads\n",
    "    interpreter = tf.lite.Interpreter(model_path=modelpath)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get model details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    height = input_details[0]['shape'][1]\n",
    "    width = input_details[0]['shape'][2]\n",
    "\n",
    "    # Open webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    last_person_time = time.time()\n",
    "    lights_on = False\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture frame\")\n",
    "            break\n",
    "\n",
    "        # Resize frame to expected shape [1xHxWx3]\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        imH, imW, _ = frame.shape\n",
    "        image_resized = cv2.resize(image_rgb, (width, height))\n",
    "\n",
    "        # Normalize pixel values and convert data type to FLOAT32\n",
    "        input_data = np.expand_dims(image_resized.astype(np.float32) / 255.0, axis=0)\n",
    "\n",
    "        # Perform object detection by running the model with the frame as input\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Retrieve detection results\n",
    "        boxes = interpreter.get_tensor(output_details[1]['index'])[0]  # Bounding box coordinates of detected objects\n",
    "        classes = interpreter.get_tensor(output_details[3]['index'])[0]  # Class index of detected objects\n",
    "        scores = interpreter.get_tensor(output_details[0]['index'])[0]  # Confidence of detected objects\n",
    "\n",
    "        person_detected = False\n",
    "\n",
    "        for i in range(len(scores)):\n",
    "            if ((scores[i] > min_conf) and (scores[i] <= 1.0)):\n",
    "                detected_label = labels[int(classes[i])]\n",
    "                if detected_label == 'person' and scores[i] > 0.7:\n",
    "                    person_detected = True\n",
    "                    last_person_time = time.time()\n",
    "                    if not lights_on:\n",
    "                        print('Lights ON')\n",
    "                        send_command_to_arduino('ON')\n",
    "                        lights_on = True\n",
    "\n",
    "                # Draw rectangle and label on the frame\n",
    "                xmin = int(max(1, (boxes[i][1] * imW)))\n",
    "                ymin = int(max(1, (boxes[i][0] * imH)))\n",
    "                xmax = int(min(imW, (boxes[i][3] * imW)))\n",
    "                ymax = int(min(imH, (boxes[i][2] * imH)))\n",
    "                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n",
    "                object_name = labels[int(classes[i])]\n",
    "                label = '%s: %d%%' % (object_name, int(scores[i] * 100))\n",
    "                labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
    "                label_ymin = max(ymin, labelSize[1] + 10)\n",
    "                cv2.rectangle(frame, (xmin, label_ymin - labelSize[1] - 10),\n",
    "                              (xmin + labelSize[0], label_ymin + baseLine - 10), (255, 255, 255), cv2.FILLED)\n",
    "                cv2.putText(frame, label, (xmin, label_ymin - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "\n",
    "        # Check if no person detected for 15 seconds\n",
    "        if not person_detected and time.time() - last_person_time >= 6 and lights_on:\n",
    "            print('Lights OFF')\n",
    "            send_command_to_arduino('OFF')\n",
    "            lights_on = False\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Smart Light', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit the loop\n",
    "            break\n",
    "\n",
    "    # Release video capture and close serial connection\n",
    "    cap.release()\n",
    "    serialInst.close()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Set up variables for running the user's model\n",
    "PATH_TO_MODEL = 'your_model_path_here'   # Path to .tflite model file\n",
    "PATH_TO_LABELS = 'your_model_label_path_here'   # Path to labelmap.txt file\n",
    "min_conf_threshold = 0.5   # Confidence threshold\n",
    "\n",
    "# Run real-time object detection!\n",
    "tflite_realtime_detection(PATH_TO_MODEL, PATH_TO_LABELS, min_conf_threshold)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
